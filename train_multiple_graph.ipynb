{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "metadata": {
        "id": "pKmQ41LclIGu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "dcwGi3SH7NcN",
        "outputId": "b08007ce-b57b-46c8-8cec-302ed2d25701",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-f6b9f2b7-d89a-d9c0-cd71-8671b914793c)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "    !git clone https://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@github.com/arunsammit/MPNN-Ptr mpnn_ptr\n",
        "    !rsync -a mpnn_ptr/* . \n",
        "    !rm mpnn_ptr -r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hwsmwyGjkuW",
        "outputId": "16e4d0d9-9b4c-4a36-89ee-da132812839f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mpnn_ptr'...\n",
            "remote: Enumerating objects: 676, done.\u001b[K\n",
            "remote: Counting objects: 100% (676/676), done.\u001b[K\n",
            "remote: Compressing objects: 100% (471/471), done.\u001b[K\n",
            "remote: Total 676 (delta 326), reused 521 (delta 193), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (676/676), 117.33 MiB | 21.76 MiB/s, done.\n",
            "Resolving deltas: 100% (326/326), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB: \n",
        "    !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cu111.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnzh012VmhYk",
        "outputId": "e8439bc7-7d61-4c78-f526-353a4a659f3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 12.1 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 55.5 MB/s \n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 60.9 MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (747 kB)\n",
            "\u001b[K     |████████████████████████████████| 747 kB 33.2 MB/s \n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 16.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 766 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581968 sha256=410bb4e306d520dd4fdde052cf72e03fd2a20a9921c2a3377640eeed9a9b96ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-spline-conv, torch-sparse, torch-scatter, torch-geometric, torch-cluster\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-cluster-1.5.9 torch-geometric-2.0.3 torch-scatter-2.0.9 torch-sparse-0.6.12 torch-spline-conv-1.2.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2H-SWyypHa4",
        "outputId": "88208679-61a0-4dd0-bfa6-ed8c0bbf7c52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/MyDrive/data_MTP/data_tgff.zip -d ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBsg9_P-qtP7",
        "outputId": "c4b4f09d-205c-4cac-cd1b-1d86d3f770bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/data_MTP/data_tgff.zip\n",
            "   creating: ./data_tgff/\n",
            "   creating: ./data_tgff/multiple/\n",
            "   creating: ./data_tgff/multiple/test/\n",
            "   creating: ./data_tgff/multiple/test/processed/\n",
            "  inflating: ./data_tgff/multiple/test/processed/pre_transform.pt  \n",
            "  inflating: ./data_tgff/multiple/test/processed/data.pt  \n",
            "  inflating: ./data_tgff/multiple/test/processed/pre_filter.pt  \n",
            "  inflating: ./data_tgff/multiple/test/processed/start_pos_data.pt  \n",
            "  inflating: ./data_tgff/multiple/test/data_sizes.txt  \n",
            "   creating: ./data_tgff/multiple/test/raw/\n",
            "  inflating: ./data_tgff/multiple/test/raw/testdata_multiple_TGFF_norm_121.pt  \n",
            "  inflating: ./data_tgff/multiple/test/raw/testdata_multiple_TGFF_norm_64.pt  \n",
            "  inflating: ./data_tgff/multiple/test/raw/testdata_multiple_TGFF_norm_32.pt  \n",
            "  inflating: ./data_tgff/multiple/test/raw/testdata_multiple_TGFF_norm_81.pt  \n",
            "  inflating: ./data_tgff/multiple/test/raw/testdata_multiple_TGFF_norm_16.pt  \n",
            "   creating: ./data_tgff/multiple/train/\n",
            "   creating: ./data_tgff/multiple/train/processed/\n",
            "  inflating: ./data_tgff/multiple/train/processed/pre_transform.pt  \n",
            "  inflating: ./data_tgff/multiple/train/processed/data.pt  \n",
            "  inflating: ./data_tgff/multiple/train/processed/pre_filter.pt  \n",
            "  inflating: ./data_tgff/multiple/train/processed/start_pos_data.pt  \n",
            "  inflating: ./data_tgff/multiple/train/data_bugs.txt  \n",
            "  inflating: ./data_tgff/multiple/train/traindata_sizes.txt  \n",
            " extracting: ./data_tgff/multiple/train/data_sizes.txt  \n",
            "   creating: ./data_tgff/multiple/train/raw/\n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_56.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_81.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_49.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_30.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_16.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_20.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_36.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_64.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_12.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_72.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_9.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_25.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_42.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_100.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_90.pt  \n",
            "  inflating: ./data_tgff/multiple/train/raw/traindata_multiple_TGFF_norm_121.pt  \n",
            "   creating: ./data_tgff/single/\n",
            "  inflating: ./data_tgff/single/data_single_TGFF4_16.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF5_81.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF2_16.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF2_64.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF3_64.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF1_16.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF5_64.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF2_81.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF4_64.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF5_16.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF3_16.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF4_81.pt  \n",
            "  inflating: ./data_tgff/single/data_single_TGFF3_81.pt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm data_tgff/multiple/train/processed -r\n",
        "!rm data_tgff/multiple/test/processed -r"
      ],
      "metadata": {
        "id": "uiQP1sySEEx4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hHbVc6stjXuT"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader.dataloader import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "from models.mpnn_ptr import MpnnPtr\n",
        "from utils.utils import init_weights\n",
        "from utils.datagenerate import generate_distance_matrix, DistanceMatrix\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from graphdataset import MultipleGraphDataset, getDataLoader\n",
        "from train.trainers import TrainerInitPop, TrainerSR\n",
        "from train.validation import validate_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xjheY8JXjXuc"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "max_graph_size = 121\n",
        "batch_size_train = 32\n",
        "batch_size_dev = 64\n",
        "saved_model_path = None\n",
        "lr = 0.001\n",
        "lr_decay_gamma = .96\n",
        "num_epochs = 50\n",
        "num_samples = 8\n",
        "training_algorithm = 'init_pop' # 'init_pop' or 'pretrain'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R6JNHpv6jXud"
      },
      "outputs": [],
      "source": [
        "root_train = 'data_tgff/multiple/train'\n",
        "root_dev = 'data_tgff/multiple/test'\n",
        "train_good_files = ['traindata_multiple_TGFF_norm_12.pt', 'traindata_multiple_TGFF_norm_16.pt', 'traindata_multiple_TGFF_norm_20.pt', 'traindata_multiple_TGFF_norm_36.pt', 'traindata_multiple_TGFF_norm_49.pt', 'traindata_multiple_TGFF_norm_56.pt', 'traindata_multiple_TGFF_norm_64.pt', 'traindata_multiple_TGFF_norm_72.pt', 'traindata_multiple_TGFF_norm_81.pt', 'traindata_multiple_TGFF_norm_90.pt', 'traindata_multiple_TGFF_norm_100.pt', 'traindata_multiple_TGFF_norm_121.pt']\n",
        "dev_good_files = ['testdata_multiple_TGFF_norm_16.pt', 'testdata_multiple_TGFF_norm_32.pt', 'testdata_multiple_TGFF_norm_64.pt', 'testdata_multiple_TGFF_norm_81.pt', 'testdata_multiple_TGFF_norm_121.pt']\n",
        "train_dataloader = getDataLoader('data_tgff/multiple/train', batch_size_train, max_graph_size = max_graph_size, raw_file_names = train_good_files)\n",
        "dev_dataloader = getDataLoader('data_tgff/multiple/test', batch_size_dev, max_graph_size = max_graph_size, raw_file_names = dev_good_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRVC_thNjXue",
        "outputId": "f0ce3251-f056-4796-b6de-6026ded14063"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MpnnPtr(\n",
              "  (mpnn): Mpnn()\n",
              "  (ptr_net): PointerNet(\n",
              "    (encoder): Encoder(\n",
              "      (rnn): LSTM(131, 141, num_layers=2, dropout=0.1)\n",
              "    )\n",
              "    (decoder): Decoder(\n",
              "      (rnn): LSTM(131, 141, num_layers=2, dropout=0.1)\n",
              "    )\n",
              "    (attn): Attention(\n",
              "      (attn): Sequential(\n",
              "        (0): Linear(in_features=282, out_features=141, bias=True)\n",
              "        (1): Tanh()\n",
              "      )\n",
              "      (v): Linear(in_features=141, out_features=1, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "mpnn_ptr = MpnnPtr(input_dim=max_graph_size, embedding_dim=max_graph_size + 10, hidden_dim=max_graph_size + 20, K=3, n_layers=2, p_dropout=0.1, device=device, logit_clipping=True)\n",
        "mpnn_ptr.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Tb0H5EYNjXuf"
      },
      "outputs": [],
      "source": [
        "if saved_model_path:\n",
        "    mpnn_ptr.load_state_dict(torch.load(sys.argv[5],map_location=device))\n",
        "else:\n",
        "    mpnn_ptr.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3C96pt17jXug"
      },
      "outputs": [],
      "source": [
        "if training_algorithm == 'init_pop':\n",
        "    trainer = TrainerInitPop(mpnn_ptr, num_samples + 1)\n",
        "elif training_algorithm == 'pretrain':\n",
        "    trainer = TrainerSR(mpnn_ptr, num_samples)\n",
        "distance_matrix_dict = DistanceMatrix()\n",
        "optim = torch.optim.Adam(mpnn_ptr.parameters(), lr=lr)\n",
        "lr_schedular = torch.optim.lr_scheduler.StepLR(optim, step_size=1, gamma=lr_decay_gamma)\n",
        "loss_list_train = []\n",
        "loss_list_dev = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F48XFAw4jXui",
        "outputId": "2a65b3f2-17f0-4169-e074-19194b937eaf"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating distance matrix for graph size 16\n",
            "Generating distance matrix for graph size 72\n",
            "Generating distance matrix for graph size 64\n",
            "Generating distance matrix for graph size 56\n",
            "Generating distance matrix for graph size 121\n",
            "Generating distance matrix for graph size 20\n",
            "Generating distance matrix for graph size 12\n",
            "Generating distance matrix for graph size 49\n",
            "Generating distance matrix for graph size 100\n",
            "Generating distance matrix for graph size 36\n",
            "Generating distance matrix for graph size 90\n",
            "Generating distance matrix for graph size 81\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    avg_train_comm_cost = trainer.train(train_dataloader, distance_matrix_dict, optim)\n",
        "    lr_schedular.step()\n",
        "    loss_list_train.append(avg_train_comm_cost)\n",
        "    avg_valid_comm_cost = validate_dataloader(dev_dataloader, mpnn_ptr, distance_matrix_dict)\n",
        "    loss_list_dev.append(avg_valid_comm_cost)\n",
        "    print(f'Epoch: {epoch + 1}/{num_epochs}, Train Comm Cost: {avg_train_comm_cost:.4f}, Dev Comm Cost: {avg_valid_comm_cost:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwM7D43VjXuk"
      },
      "outputs": [],
      "source": [
        "# save the model\n",
        "datetime_suffix = datetime.now().strftime('%m-%d_%H-%M')\n",
        "torch.save(mpnn_ptr.state_dict(), f'models_data/model_{training_algorithm}_{max_graph_size}_{datetime_suffix}.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sigtNbF8jXul"
      },
      "outputs": [],
      "source": [
        "# plot loss_list_pre\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(loss_list_train)\n",
        "ax.plot(loss_list_dev)\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Communication cost')\n",
        "fig.savefig(f'plots/loss_list_{max_graph_size}_{datetime_suffix}.png', dpi=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdH1sgCdjXum"
      },
      "outputs": [],
      "source": [
        "torch.save(loss_list_train, f'plots/loss_list_train_{training_algorithm}_{max_graph_size}_{datetime_suffix}.pt')\n",
        "torch.save(loss_list_dev, f'plots/loss_list_dev_{training_algorithm}_{max_graph_size}_{datetime_suffix}.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1pBpRWSjXun"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "train_multiple_graph.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  }
}